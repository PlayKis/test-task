from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum, rank, year
from pyspark.sql.window import Window

print("üöÄ –ó–∞–ø—É—Å–∫ Spark –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")

# ... (–Ω–∞—á–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º SparkSession –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
spark = (
    SparkSession.builder
    .appName("Top 3 Stores by City") \
    # –í –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–º –æ–±—Ä–∞–∑–µ Spark –Ω–µ—Ç S3A –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    .config(
        "spark.jars.packages",
        "org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262",
    ) \
    .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000") \
    .config("spark.hadoop.fs.s3a.access.key", "admin") \
    .config("spark.hadoop.fs.s3a.secret.key", "password123") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
    .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false") \
    .config(
        "spark.hadoop.fs.s3a.aws.credentials.provider",
        "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider",
    ) \
    .getOrCreate()
)

print("‚úÖ SparkSession —Å–æ–∑–¥–∞–Ω–∞")

try:
    # 1. –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Minio (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    print("\nüìñ –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Minio...")
    users = spark.read.parquet("s3a://data-lake/input/user.parquet")
    stores = spark.read.parquet("s3a://data-lake/input/store.parquet")
    orders = spark.read.parquet("s3a://data-lake/input/order.parquet")

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ö–µ–º—É –ø–æ–¥ –¢–ó:
    # user: id,name,phone,created_at
    # store: id,name,city
    # order: id,amount,user_id,store_id,status,created_at
    if "id" in users.columns and "user_id" not in users.columns:
        users = users.withColumnRenamed("id", "user_id")
    if "id" in stores.columns and "store_id" not in stores.columns:
        stores = stores.withColumnRenamed("id", "store_id")
    if "name" in stores.columns and "store_name" not in stores.columns:
        stores = stores.withColumnRenamed("name", "store_name")
    if "id" in orders.columns and "order_id" not in orders.columns:
        orders = orders.withColumnRenamed("id", "order_id")

    print(f"   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {users.count()}")
    print(f"   –ú–∞–≥–∞–∑–∏–Ω–æ–≤: {stores.count()}")
    print(f"   –ó–∞–∫–∞–∑–æ–≤: {orders.count()}")

    # 2. –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π 2025 –≥–æ–¥–∞ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    print("\nüîç –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π 2025 –≥–æ–¥–∞...")
    users_2025 = users.filter(year("created_at") == 2025)
    print(f"   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π 2025 –≥–æ–¥–∞: {users_2025.count()}")

    # 3. –î–∂–æ–π–Ω–∏–º —Ç–∞–±–ª–∏—Ü—ã
    print("\nüîó –°–æ–µ–¥–∏–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—ã...")
    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–µ–¥–∏–Ω—è–µ–º –∑–∞–∫–∞–∑—ã —Å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏
    orders_with_users = orders.join(users_2025, "user_id", "inner")

    # –ó–∞—Ç–µ–º —Å–æ–µ–¥–∏–Ω—è–µ–º —Å –º–∞–≥–∞–∑–∏–Ω–∞–º–∏. –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫–∏–µ —Å—Ç–æ–ª–±—Ü—ã –±—Ä–∞—Ç—å –ø–æ—Å–ª–µ JOIN,
    # —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –∏–º–µ–Ω 'city'.
    # –ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–æ—Ä–æ–¥ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –º–∞–≥–∞–∑–∏–Ω–æ–≤ (stores.city) –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π.
    joined_data = orders_with_users.join(stores, "store_id", "inner") \
        .select(
        orders_with_users["*"],  # –≤—Å–µ –ø–æ–ª—è –∏–∑ orders_with_users
        stores["store_name"],  # –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞
        stores["city"].alias("store_city")  # –≥–æ—Ä–æ–¥ –º–∞–≥–∞–∑–∏–Ω–∞ —Å –ø–æ–Ω—è—Ç–Ω—ã–º –∞–ª–∏–∞—Å–æ–º
    )

    # 4. –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º: –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≥–æ—Ä–æ–¥—É –º–∞–≥–∞–∑–∏–Ω–∞ (store_city) –∏ –º–∞–≥–∞–∑–∏–Ω—É
    print("\nüìä –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ...")
    result = joined_data.groupBy("store_id", "store_name", "store_city") \
        .agg(sum("amount").alias("target_amount"))

    # 5. –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–Ω–≥ –∏ –±–µ—Ä–µ–º —Ç–æ–ø-3 –ø–æ –∫–∞–∂–¥–æ–º—É –≥–æ—Ä–æ–¥—É
    print("\nüèÜ –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ–ø-3 –º–∞–≥–∞–∑–∏–Ω–∞ –ø–æ –≥–æ—Ä–æ–¥–∞–º...")
    window_spec = Window.partitionBy("store_city").orderBy(col("target_amount").desc())
    top_stores = result \
        .withColumn("rank", rank().over(window_spec)) \
        .filter(col("rank") <= 3) \
        .drop("rank") \
        .withColumnRenamed("store_city", "city")  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã

    # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Minio...")
    top_stores.write \
        .mode("overwrite") \
        .parquet("s3a://data-lake/output/top_stores.parquet")
    print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ s3a://data-lake/output/top_stores.parquet")

    # 7. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    print("\nüìä –¢–æ–ø-3 –º–∞–≥–∞–∑–∏–Ω–∞ –ø–æ –≥–æ—Ä–æ–¥–∞–º:")
    print("=" * 60)
    top_stores.show(20, truncate=False)
    print("=" * 60)

except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    import traceback

    traceback.print_exc()

finally:
    spark.stop()
    print("\nüèÅ Spark –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")